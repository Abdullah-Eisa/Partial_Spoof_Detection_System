
# Training configuration
training:
  num_epochs: &num_epochs 30
  # num_epochs: &num_epochs 15
  learning_rate: &learning_rate 0.00075
  batch_size: &batch_size 8
  save_interval: 5
  patience: 15
  max_grad_norm: 1.0
  gamma: 0.9
  monitor_dev_epoch: 0
  use_wandb: true

# WandB sweep configuration
wandb_sweep:
  NUM_EPOCHS:
    values: [*num_epochs]
  LEARNING_RATE:
    values: [*learning_rate]
  BATCH_SIZE:
    values: [*batch_size]



# Feature Extractor configuration
feature_extractor:
  type: "wav2vec2"  # Options: "wav2vec2", "hubert", "mfcc", "lfcc"
  # type: "hubert"
  # type: "mfcc"
  # type: "lfcc"

  # SSL models (wav2vec2, hubert)
  ssl_checkpoint: "${BASE_DIR}/models/w2v_large_lv_fsh_swbd_cv.pt"
  # ssl_checkpoint: "${BASE_DIR}/models/hubert-large-ls960-ft"
  
  # MFCC parameters
  mfcc_n_mfcc: 40
  mfcc_log_mels: true
  mfcc_sample_rate: 16000
  mfcc_n_fft: 400
  mfcc_hop_length: 160
  # mfcc_n_mels: 80
  mfcc_n_mels: 40


  # LFCC parameters
  # lfcc_n_filters: 20
  # lfcc_n_lfcc: 40
  lfcc_n_filters: 80
  lfcc_n_lfcc: 56
  lfcc_sample_rate: 16000
  lfcc_n_fft: 512
  lfcc_hop_length: 160


# Model configuration  
model:
  # feature_dim: 768  # 768 for wav2vec2/hubert, 40 for mfcc/lfcc
  feature_dim: 768  # 768 for wav2vec2/hubert, 40 for mfcc/lfcc
  num_heads: 8
  hidden_dim: 128
  max_dropout: 0.35
  depthwise_conv_kernel_size: 31
  conformer_layers: 1
  max_pooling_factor: 3
  use_max_pooling: false  # Set to false for small feature dims like MFCC/LFCC
  
  # Pooling strategy configuration
  # Options: "self_weighted", "max", "average", "attention", "strided_conv"
  # pooling_strategy: "self_weighted"  # Default pooling strategy
  pooling_strategy: "strided_conv"  
  
  # ====== Sequence Model Configuration ======
  # Options: 'conformer', 'lstm', 'transformer', 'cnn', 'tcn'
  sequence_model_type: 'conformer'
  
  # Additional sequence model configuration (optional)
  # If not specified, defaults will be used based on conformer_layers and hidden_dim
  sequence_model_config: {}
  
  # ====== EXAMPLE CONFIGURATIONS FOR EACH MODEL TYPE ======
  # Uncomment and modify the sequence_model_config section below for specific models
  
  # ===== CONFORMER CONFIG =====
  # Best for: Balanced accuracy and efficiency (combines self-attention + convolution)
  # sequence_model_config:
  #   num_heads: 8                           # Number of attention heads
  #   hidden_dim: 256                        # Feed-forward network dimension
  #   num_layers: 4                          # Number of conformer layers
  #   depthwise_conv_kernel_size: 31         # Kernel size for depthwise convolution
  #   dropout: 0.2                           # Dropout rate
  
  # ===== LSTM CONFIG =====
  # Best for: Sequence modeling with bidirectional context (RNN-based)
  # sequence_model_config:
  #   hidden_dim: 128                        # LSTM hidden dimension (output is 2x for bidirectional)
  #   num_layers: 2                          # Number of LSTM layers
  #   dropout: 0.2                           # LSTM dropout rate
  
  # ===== TRANSFORMER CONFIG =====
  # Best for: Long-range dependencies and parallel processing (attention-only)
  # sequence_model_config:
  #   num_heads: 8                           # Number of attention heads
  #   hidden_dim: 256                        # Feed-forward network dimension
  #   num_layers: 4                          # Number of transformer layers
  #   dropout: 0.2                           # Transformer dropout rate
  
  # ===== CNN CONFIG =====
  # Best for: Local feature extraction and fast inference (convolutional)
  # sequence_model_config:
  #   hidden_dim: 256                        # CNN hidden dimension
  #   num_layers: 4                          # Number of CNN layers
  #   kernel_size: 3                         # Convolution kernel size
  #   dropout: 0.2                           # CNN dropout rate
  
  # ===== TCN CONFIG =====
  # Best for: Sequential processing with dilated convolutions (advanced CNN)
  # sequence_model_config:
  #   hidden_dim: 256                        # TCN hidden dimension
  #   num_layers: 4                          # Number of TCN blocks (with increasing dilation)
  #   kernel_size: 3                         # Convolution kernel size
  #   dropout: 0.2                           # TCN dropout rate
  
  # Average pooling parameters
  average_pooling:
    kernel_size: 3
    stride: 3
  
  # Attention pooling (LearnedFeatureProjection) parameters
  attention_pooling:
    output_dim: 256  # Output dimension after attention projection
  
  # Strided convolution pooling parameters
  strided_conv_pooling:
    out_channels: 256
    kernel_size: 3
    stride: 3
    padding: 0

# Data configuration
data:
  # dataset_name: "PartialSpoof_Dataset"
  # base_path: "${BASE_DIR}/database"
  # train_data_path: "${BASE_DIR}/database/PartialSpoof/database/train/con_wav"
  # train_labels_path: "${BASE_DIR}/database/utterance_labels/PartialSpoof_LA_cm_train_trl.json"
  # dev_data_path: "${BASE_DIR}/database/PartialSpoof/database/dev/con_wav"
  # dev_labels_path: "${BASE_DIR}/database/utterance_labels/PartialSpoof_LA_cm_dev_trl.json"
  # eval_data_path: "${BASE_DIR}/database/PartialSpoof/database/eval/con_wav"
  # eval_labels_path: "${BASE_DIR}/database/utterance_labels/PartialSpoof_LA_cm_eval_trl.json"

  # dataset_name: "RFP_Dataset"
  # base_path: "${BASE_DIR}/database"
  # train_data_path: "${BASE_DIR}/database/RFP/training"
  # train_labels_path: "${BASE_DIR}/database/RFP/labels/ASVspoof2017_V2_train.trl.txt"
  # dev_data_path: "${BASE_DIR}/database/RFP/validation"
  # dev_labels_path: "${BASE_DIR}/database/RFP/labels/ASVspoof2017_V2_dev.trl.txt"
  # eval_data_path: "${BASE_DIR}/database/RFP/testing"
  # eval_labels_path: "${BASE_DIR}/database/RFP/labels/ASVspoof2017_V2_eval.trl.txt"

  dataset_name: "ASVspoof2019_LA_Dataset"
  base_path: "${BASE_DIR}/database"
  train_data_path: "${BASE_DIR}/database/ASVspoof2019/LA/ASVspoof2019_LA_train/flac"
  train_labels_path: "${BASE_DIR}/database/ASVspoof2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt"
  dev_data_path: "${BASE_DIR}/database/ASVspoof2019/LA/ASVspoof2019_LA_dev/flac"
  dev_labels_path: "${BASE_DIR}/database/ASVspoof2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt"
  eval_data_path: "${BASE_DIR}/database/ASVspoof2019/LA/ASVspoof2019_LA_eval/flac"
  eval_labels_path: "${BASE_DIR}/database/ASVspoof2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt"


# Model paths
paths:
  ssl_checkpoint: "${BASE_DIR}/models/w2v_large_lv_fsh_swbd_cv.pt"
  model_save_dir: "${BASE_DIR}/models/back_end_models"
  wandb_key_file: "${BASE_DIR}/config/wandb_key.txt"
  # Add the PS model checkpoint path
  # ps_model_checkpoint: "${BASE_DIR}/models/back_end_models/model.pth"
  # ps_model_checkpoint: "${BASE_DIR}/models/back_end_models/ASVspoof2019_LA_Dataset_model_epochs15_batch8_lr0.00075_20260102_162234.pth"
  ps_model_checkpoint: "${BASE_DIR}/models/back_end_models/ASVspoof2019_LA_Dataset_model_epochs15_batch8_lr0.00075_20260102_200317.pth"


# Inference configuration
inference:
  use_cuda: true
  # batch_size: 16
  batch_size: 4
  # num_workers: 8
  num_workers: 2
  prefetch_factor: 2
  pin_memory: true
  apply_transform: false

# System configuration
system:
  num_workers: 8
  prefetch_factor: 2
  pin_memory: true
  device: "cuda"  # Will be overridden based on availability
  apply_transform: false
  save_feature_extractor: false

